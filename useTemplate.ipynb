{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:38:14.846193Z",
     "start_time": "2024-01-22T10:38:14.803823Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "seed = 11032\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, init_weights=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(1, 8)),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 128, 8)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = x.squeeze(3)\n",
    "        x = self.encoder_layer(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:39:49.301425Z",
     "start_time": "2024-01-22T10:39:49.265083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class argparse():\n",
    "    pass\n",
    "\n",
    "args = argparse()\n",
    "args.epochs, args.learning_rate, args.train_batch_size, args.test_batch_size = [1000, 0.001, 2048, 2048]\n",
    "args.device, = [torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:40:29.080662Z",
     "start_time": "2024-01-22T10:40:29.037756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class Dataset_CAR(Dataset):\n",
    "    def __init__(self, flag='train', csv_paths = []):\n",
    "        assert flag in ['train', 'test'] # flag 必须是train  test 之间的其中一个\n",
    "        self.flag = flag\n",
    "        self.__load_data__(csv_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __load_data__(self, csv_paths: list):\n",
    "        # 读取 排列按照 train feature train label test feature test label\n",
    "        self.x = torch.tensor(pd.read_csv(csv_paths[0]).values)\n",
    "        self.y = torch.tensor(pd.read_csv(csv_paths[1], header = None).values) # 因为 label的表头是没有的，所以使用 header  = None\n",
    "        print(\"feature shape: {}, label shape: {}\".format(self.x.shape, self.y.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:40:43.250034Z",
     "start_time": "2024-01-22T10:40:43.200529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape: torch.Size([33175, 1024]), label shape: torch.Size([33175, 1])\n"
     ]
    }
   ],
   "source": [
    "csv_path_train = ['K_onlySMOTE_x.csv', 'K_onlySMOTE_y.csv']\n",
    "train_dataset = Dataset_CAR(flag='train', csv_paths=csv_path_train)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size = args.train_batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:40:57.910418Z",
     "start_time": "2024-01-22T10:40:46.855182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape: torch.Size([7556, 1024]), label shape: torch.Size([7556, 1])\n"
     ]
    }
   ],
   "source": [
    "csv_path_test = [\"K_test_feature.csv\", \"K_test_y.csv\"]\n",
    "test_dataset = Dataset_CAR(flag='test', csv_paths=csv_path_test)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size = args.test_batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:41:00.470192Z",
     "start_time": "2024-01-22T10:40:58.441839Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model = Model().to(args.device)\n",
    "criterion = nn.BCELoss()  # 二元交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)  # Adam 优化器\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_epochs_loss = []\n",
    "test_epochs_loss = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:41:55.583760Z",
     "start_time": "2024-01-22T10:41:55.537335Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4778],\n",
      "        [0.4723],\n",
      "        [0.4875],\n",
      "        ...,\n",
      "        [0.4720],\n",
      "        [0.4798],\n",
      "        [0.4735]], grad_fn=<SigmoidBackward0>)\n",
      "epoch=0/100,0/33of train, loss=48.61852264404297\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7306/523420641.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mtrain_epoch_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdata_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_y\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m         \u001B[0mdata_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata_x\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mdata_y\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata_y\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    626\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    627\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 628\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    629\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 671\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    672\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    673\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory_device\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollate_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001B[0m in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    263\u001B[0m             \u001B[0;34m>>\u001B[0m\u001B[0;34m>\u001B[0m \u001B[0mdefault_collate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Handle `CustomType` automatically\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m     \"\"\"\n\u001B[0;32m--> 265\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mcollate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdefault_collate_fn_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001B[0m in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melem\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0melem_size\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0melem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mit\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'each element in list of batch should be of equal size'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m         \u001B[0mtransposed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# It may be accessed twice, so we use a list.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "# 需要重新进行修改\n",
    "# for epoch in range(args.epochs):\n",
    "#     model.train()\n",
    "#     train_epoch_loss = []\n",
    "#     for idx, (data_x, data_y) in enumerate(train_dataloader, 0):\n",
    "#         data_x = data_x.to(torch.float32).to(args.device)\n",
    "#         data_y = data_y.to(torch.float32).to(args.device)\n",
    "#         outputs = model(data_x)\n",
    "#         print(outputs) # output 输出的内容为 nan\n",
    "#         loss = criterion(data_y, outputs)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#         train_epoch_loss.append(loss.item())\n",
    "#         train_loss.append(loss.item())\n",
    "#\n",
    "#         if idx %(len(train_dataloader)//2)==0:\n",
    "#             print(\"epoch={}/{},{}/{}of train, loss={}\".format(epoch, args.epochs, idx, len(train_dataloader),loss.item()))\n",
    "#     train_epochs_loss.append(np.average(train_epoch_loss))\n",
    "#\n",
    "#     #=====================valid============================\n",
    "#\n",
    "#     model.eval()\n",
    "#     test_epoch_loss = []\n",
    "#     for idx, (data_x, data_y) in enumerate(test_dataloader, 0):\n",
    "#         data_x = data_x.to(torch.float32).to(args.device)\n",
    "#         data_y = data_y.to(torch.float32).to(args.device)\n",
    "#\n",
    "#         outputs = model(data_x)\n",
    "#\n",
    "#         loss = criterion(data_y, outputs)\n",
    "#         test_epoch_loss.append(loss.item())\n",
    "#         test_loss.append(loss.item())\n",
    "#\n",
    "#     test_epochs_loss.append(np.average(test_epoch_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:32:09.474113Z",
     "start_time": "2024-01-22T10:32:03.144174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.1851887  0.18460917 0.18422025 ... 0.18475303 0.18436344 0.18424201]\n",
      "Epoch [1/1000], Loss: 0.4426, Accuracy: 98.45%\n",
      "0.5558117704911629\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.17504834 0.1753831  0.17524515 ... 0.17521288 0.17505042 0.1751945 ]\n",
      "Epoch [2/1000], Loss: 0.4925, Accuracy: 98.45%\n",
      "0.5829251703025059\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.17923395 0.17918786 0.17913723 ... 0.1793927  0.17918591 0.17956166]\n",
      "Epoch [3/1000], Loss: 0.4388, Accuracy: 98.45%\n",
      "0.5876645721382917\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 1 0 0]\n",
      "[0.19724391 0.19654565 0.19650452 ... 0.19568844 0.19675286 0.19625108]\n",
      "Epoch [4/1000], Loss: 0.4990, Accuracy: 98.45%\n",
      "0.5821628446981317\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.18637641 0.18665145 0.18497607 ... 0.18656689 0.18654698 0.18514559]\n",
      "Epoch [5/1000], Loss: 0.4460, Accuracy: 98.45%\n",
      "0.5896183546405349\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.17568508 0.17369062 0.17660142 ... 0.17654389 0.17719738 0.17666565]\n",
      "Epoch [6/1000], Loss: 0.4302, Accuracy: 98.45%\n",
      "0.5919265869528001\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.17992884 0.17652152 0.17896393 ... 0.1803783  0.18305543 0.17485368]\n",
      "Epoch [7/1000], Loss: 0.4612, Accuracy: 98.45%\n",
      "0.59231378172096\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.21649654 0.21567044 0.20927656 ... 0.19962755 0.1893891  0.18049031]\n",
      "Epoch [8/1000], Loss: 0.5057, Accuracy: 98.45%\n",
      "0.5898435480368536\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.23703323 0.2572982  0.2927214  ... 0.18649298 0.2790633  0.15560248]\n",
      "Epoch [9/1000], Loss: 0.4999, Accuracy: 98.45%\n",
      "0.59988935650987\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.20913832 0.09117744 0.22076093 ... 0.19795908 0.11884639 0.11170022]\n",
      "Epoch [10/1000], Loss: 0.4184, Accuracy: 98.45%\n",
      "0.618863623568557\n",
      "TP: 0, FP: 0, Sensitivity (SN): 0.0, Specificity (SP): 1.0, Matthews Correlation Coefficient (MCC): 0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.05313472 0.05098038 0.06920772 ... 0.12067825 0.05976779 0.22880122]\n",
      "Epoch [11/1000], Loss: 0.3581, Accuracy: 98.45%\n",
      "0.6751125679745119\n",
      "TP: 10, FP: 152, Sensitivity (SN): 0.08547008547008547, Specificity (SP): 0.9795671461217905, Matthews Correlation Coefficient (MCC): 0.055438953850501974\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.10285299 0.08525828 0.12129363 ... 0.05006739 0.04040106 0.1980651 ]\n",
      "Epoch [12/1000], Loss: 0.3881, Accuracy: 96.57%\n",
      "0.694357411792551\n",
      "TP: 13, FP: 228, Sensitivity (SN): 0.1111111111111111, Specificity (SP): 0.9693507191826859, Matthews Correlation Coefficient (MCC): 0.056535915748344066\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.1990218  0.08482903 0.08307845 ... 0.25214246 0.0310363  0.04546595]\n",
      "Epoch [13/1000], Loss: 0.2717, Accuracy: 95.61%\n",
      "0.6821452658258681\n",
      "TP: 12, FP: 265, Sensitivity (SN): 0.10256410256410256, Specificity (SP): 0.9643769323833848, Matthews Correlation Coefficient (MCC): 0.043981181151612904\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.02542096 0.1480567  0.01089865 ... 0.04992745 0.06428422 0.00365626]\n",
      "Epoch [14/1000], Loss: 0.2214, Accuracy: 95.10%\n",
      "0.6685405974288888\n",
      "TP: 18, FP: 371, Sensitivity (SN): 0.15384615384615385, Specificity (SP): 0.9501277053367388, Matthews Correlation Coefficient (MCC): 0.05809394527100458\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.263121   0.0200113  0.0632446  ... 0.13142383 0.25561047 0.06229711]\n",
      "Epoch [15/1000], Loss: 0.1799, Accuracy: 93.78%\n",
      "0.6642331992513468\n",
      "TP: 18, FP: 343, Sensitivity (SN): 0.15384615384615385, Specificity (SP): 0.9538916521037774, Matthews Correlation Coefficient (MCC): 0.06236620776175393\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.0060912  0.06388099 0.00511697 ... 0.00292514 0.00243482 0.03609148]\n",
      "Epoch [16/1000], Loss: 0.1857, Accuracy: 94.15%\n",
      "0.6660772574201799\n",
      "TP: 11, FP: 247, Sensitivity (SN): 0.09401709401709402, Specificity (SP): 0.9667966124479097, Matthews Correlation Coefficient (MCC): 0.04134660939398497\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00254533 0.16885492 0.00622045 ... 0.02616062 0.04793246 0.00281091]\n",
      "Epoch [17/1000], Loss: 0.1830, Accuracy: 95.33%\n",
      "0.6520003722584714\n",
      "TP: 2, FP: 80, Sensitivity (SN): 0.017094017094017096, Specificity (SP): 0.9892458663798898, Matthews Correlation Coefficient (MCC): 0.007555235620592374\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00942971 0.09137616 0.00142199 ... 0.00695588 0.00935466 0.12525053]\n",
      "Epoch [18/1000], Loss: 0.1283, Accuracy: 97.42%\n",
      "0.645706446620548\n",
      "TP: 7, FP: 112, Sensitivity (SN): 0.05982905982905983, Specificity (SP): 0.9849442129318456, Matthews Correlation Coefficient (MCC): 0.044401401613830736\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.01511561 0.00985754 0.01530231 ... 0.01411306 0.00469777 0.00724996]\n",
      "Epoch [19/1000], Loss: 0.0999, Accuracy: 97.06%\n",
      "0.6521887993860032\n",
      "TP: 5, FP: 71, Sensitivity (SN): 0.042735042735042736, Specificity (SP): 0.9904557064121522, Matthews Correlation Coefficient (MCC): 0.041068578421421434\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.0048211  0.00844581 0.01082432 ... 0.00425114 0.02401842 0.00295375]\n",
      "Epoch [20/1000], Loss: 0.0937, Accuracy: 97.58%\n",
      "0.6536743864341659\n",
      "TP: 2, FP: 35, Sensitivity (SN): 0.017094017094017096, Specificity (SP): 0.9952950665412018, Matthews Correlation Coefficient (MCC): 0.021913335629644173\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.01358152 0.00507566 0.01474784 ... 0.00227307 0.00182155 0.00384549]\n",
      "Epoch [21/1000], Loss: 0.1019, Accuracy: 98.01%\n",
      "0.64135998428242\n",
      "TP: 3, FP: 74, Sensitivity (SN): 0.02564102564102564, Specificity (SP): 0.990052426401398, Matthews Correlation Coefficient (MCC): 0.019293080020718913\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00447773 0.0031408  0.00934904 ... 0.00484732 0.01210945 0.00535341]\n",
      "Epoch [22/1000], Loss: 0.0548, Accuracy: 97.51%\n",
      "0.6539834528811541\n",
      "TP: 5, FP: 60, Sensitivity (SN): 0.042735042735042736, Specificity (SP): 0.9919343997849174, Matthews Correlation Coefficient (MCC): 0.04635221493493397\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00826765 0.00413745 0.0053414  ... 0.66848415 0.01571243 0.00287982]\n",
      "Epoch [23/1000], Loss: 0.0818, Accuracy: 97.72%\n",
      "0.6628694004685403\n",
      "TP: 6, FP: 82, Sensitivity (SN): 0.05128205128205128, Specificity (SP): 0.988977013039387, Matthews Correlation Coefficient (MCC): 0.0463308637169036\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00229123 0.01231116 0.00713424 ... 0.01047293 0.00357545 0.01326449]\n",
      "Epoch [24/1000], Loss: 0.0781, Accuracy: 97.45%\n",
      "0.6408337670604104\n",
      "TP: 10, FP: 245, Sensitivity (SN): 0.08547008547008547, Specificity (SP): 0.9670654657884125, Matthews Correlation Coefficient (MCC): 0.03592048893578558\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.03918605 0.00438851 0.02553791 ... 0.00409695 0.01180917 0.35520542]\n",
      "Epoch [25/1000], Loss: 0.0581, Accuracy: 95.34%\n",
      "0.6461924507360721\n",
      "TP: 1, FP: 21, Sensitivity (SN): 0.008547008547008548, Specificity (SP): 0.9971770399247211, Matthews Correlation Coefficient (MCC): 0.01311684433717643\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00728707 0.00334713 0.00200594 ... 0.00373899 0.0047001  0.00589899]\n",
      "Epoch [26/1000], Loss: 0.0761, Accuracy: 98.19%\n",
      "0.6392918816631681\n",
      "TP: 4, FP: 46, Sensitivity (SN): 0.03418803418803419, Specificity (SP): 0.9938163731684366, Matthews Correlation Coefficient (MCC): 0.0426468849309716\n",
      "[1 0 0 ... 0 0 0]\n",
      "[0.00217339 0.00280968 0.00556006 ... 0.00578584 0.00187249 0.00610536]\n",
      "Epoch [27/1000], Loss: 0.0372, Accuracy: 97.90%\n",
      "0.6478561243986705\n",
      "TP: 2, FP: 26, Sensitivity (SN): 0.017094017094017096, Specificity (SP): 0.9965049065734641, Matthews Correlation Coefficient (MCC): 0.02763350191968383\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00460889 0.03151661 0.00647377 ... 0.00321413 0.044501   0.0269255 ]\n",
      "Epoch [28/1000], Loss: 0.0583, Accuracy: 98.13%\n",
      "0.6411100885492604\n",
      "TP: 8, FP: 137, Sensitivity (SN): 0.06837606837606838, Specificity (SP): 0.9815835461755612, Matthews Correlation Coefficient (MCC): 0.04496213047158904\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00355526 0.0558189  0.00402087 ... 0.00954635 0.00471308 0.01188686]\n",
      "Epoch [29/1000], Loss: 0.0797, Accuracy: 96.74%\n",
      "0.6553225493271198\n",
      "TP: 10, FP: 142, Sensitivity (SN): 0.08547008547008547, Specificity (SP): 0.9809114128243044, Matthews Correlation Coefficient (MCC): 0.058377065737843535\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.00491052 0.00356133 0.00802079 ... 0.00729777 0.00787539 0.00378207]\n",
      "Epoch [30/1000], Loss: 0.0234, Accuracy: 96.70%\n",
      "0.6462349617343568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7306/310773194.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0;31m# 反向传播和优化\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    487\u001B[0m             )\n\u001B[1;32m    488\u001B[0m         torch.autograd.backward(\n\u001B[0;32m--> 489\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    490\u001B[0m         )\n\u001B[1;32m    491\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    197\u001B[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[1;32m    198\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 199\u001B[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    200\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m def grad(\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from Measurement import compAUC\n",
    "from Measurement import SN_SP_MCC\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    for idx, (data, labels) in enumerate(train_dataloader, 0):\n",
    "        # 前向传播\n",
    "        data  = data.type(torch.float32).to(args.device)\n",
    "        outputs = model(data).to(args.device)\n",
    "        labels = labels.type(torch.float32).to(args.device)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 验证\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 在验证阶段不计算梯度\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        outputs_list = []\n",
    "        labels_list = []\n",
    "        pred_list = []\n",
    "        for idx, (data, labels) in enumerate(test_dataloader, 0):\n",
    "            data = data.type(torch.float32).to(args.device)\n",
    "            labels = labels.type(torch.float32).to(args.device)\n",
    "            outputs = model(data)\n",
    "            predicted = (outputs > 0.5).float()  # 阈值设为 0.5\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            outputs_list.append(outputs)\n",
    "            labels_list.append(labels)\n",
    "            pred_list.append(predicted)\n",
    "\n",
    "        all_outputs = torch.cat(outputs_list, dim=0)\n",
    "        all_labels = torch.cat(labels_list, dim=0)\n",
    "        all_pred = torch.cat(pred_list, dim=0)\n",
    "\n",
    "\n",
    "    SN_SP_MCC(all_labels, all_pred)\n",
    "    AUC = compAUC(all_labels, all_outputs)\n",
    "    print(f'Epoch [{epoch+1}/{args.epochs}], Loss: {loss.item():.4f}, '\n",
    "          f'Accuracy: {100 * correct / total:.2f}%')\n",
    "    print(AUC)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:12:14.889739Z",
     "start_time": "2024-01-22T10:42:54.913038Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
